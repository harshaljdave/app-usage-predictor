# App Usage Prediction System

A hybrid machine learning system that learns laptop usage patterns and predicts which application you'll use next.

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ðŸŽ¯ Overview

This project implements a **hybrid prediction system** combining three complementary ML approaches:
- **Temporal Convolutional Network (TCN)** for short-term sequential patterns
- **Skip-gram embeddings** for long-term co-usage relationships  
- **Association rules** for stable habit patterns

Trained on self-collected usage data from a Linux development workstation.

## ðŸ“Š Performance

Evaluated on 94 test samples (20% holdout, temporal split):

| Model | Hit@1 | Hit@3 | Hit@5 | MRR |
|-------|-------|-------|-------|-----|
| **Baseline** (frequency) | 27.7% | 75.5% | 97.9% | 0.529 |
| **Hybrid** (optimized) | **37.2%** | **81.9%** | **97.9%** | **0.597** |

**Key Result**: Hybrid approach achieves **34% improvement** over baseline on Hit@1.

## ðŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   X11 Window Events + Titles    â”‚
â”‚   chrome:work:github            â”‚
â”‚   terminal:app-predictor        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Feature Engineering          â”‚
â”‚  â€¢ 30-min time buckets          â”‚
â”‚  â€¢ Session extraction           â”‚
â”‚  â€¢ Cyclic time features         â”‚
â”‚  â€¢ Rolling statistics           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        â”‚        â”‚
    â–¼        â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TCN  â”‚â”‚ Emb. â”‚â”‚ Rules  â”‚
â”‚ 12h   â”‚â”‚ Co-  â”‚â”‚Stable  â”‚
â”‚memory â”‚â”‚usage â”‚â”‚habits  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜â””â”€â”€â”¬â”€â”€â”€â”˜â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚       â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Context Vec  â”‚
    â”‚  (12-dim)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Weighted Fusionâ”‚
    â”‚Î±=0.5 Î²=0.3 Î³=0.2â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    Top-K Predictions
```

### Model Components

**1. TCN (Temporal Convolutional Network)**
- Input: Last 24 buckets (12 hours) of app usage
- Architecture: 3 dilated causal conv blocks [1,2,4]
- Output: Next-app probability distribution
- Purpose: Captures short-term sequential dependencies

**2. App Embeddings** (Skip-gram)
- 16-dimensional dense vectors per app
- Trained on session co-occurrence
- Purpose: Learns "VSCode and Terminal are similar"

**3. Association Rules** (FP-Growth)
- Mines patterns like `{VSCode, Terminal} â†’ GitHub (0.81 conf)`
- 126 rules discovered (min_support=5, min_conf=0.6)
- Purpose: Stable workflow habits

## ðŸš€ Quick Start

### Installation
```bash
# Clone repository
git clone https://github.com/yourusername/app-usage-predictor
cd app-usage-predictor

# Create environment
conda create -n pattern python=3.9
conda activate pattern

# Install dependencies
pip install torch numpy pandas scikit-learn mlxtend plotly jupyter
```

### Data Collection

**Start logger** (requires X11 session):
```bash
python data_collection/logger_x11.py
```

Logger captures:
- Application focus changes
- Window titles (e.g., `chrome:work:gmail`, `terminal:project-dir`)
- Idle/lock detection (pauses logging)

Recommended: Run for **2-3 weeks** for sufficient training data.

### Training
```bash
# Train all models (baseline + TCN + embeddings + rules)
python training/train_all.py --db usage.db --output outputs/models
```

Expected output:
```
[1/6] Preprocessing data...
âœ“ Aggregated 2094 events into 588 buckets
âœ“ Vocabulary size: 6 apps

[2/6] Training baseline model...
âœ“ Baseline saved

[3/6] Building TCN dataset...
Train samples: 451, Val samples: 113

[4/6] Training TCN...
Epoch 20/20 - Train Loss: 0.317, Val Loss: 0.536
âœ“ TCN saved

[5/6] Training embeddings...
âœ“ Embeddings saved

[6/6] Mining association rules...
âœ“ Mined 63 itemsets, 126 rules
```

### Evaluation
```bash
# Run ablation study
python evaluation/ablation.py --db usage.db --models outputs/models
```

## ðŸ’» Usage Example
```python
from models.hybrid import HybridPredictor
from models.tcn_model import load_tcn
from models.embeddings import AppEmbeddings
from models.association_rules import AssociationRuleMiner
import numpy as np

# Load models
tcn_model, vocab = load_tcn("outputs/models/tcn_model.pt")
emb_model = AppEmbeddings(vocab)
emb_model.load("outputs/models/app_embeddings.pkl")
rule_miner = AssociationRuleMiner()
rule_miner.load("outputs/models/association_rules.pkl")

# Create hybrid predictor
hybrid = HybridPredictor(tcn_model, vocab, emb_model, rule_miner)

# Prepare context
context = {
    'recent_window': recent_usage_matrix,  # (24, num_apps)
    'recent_apps': ['vscode', 'terminal'],
    'timestamp': int(time.time()),
    'usage_stats': {...}  # Rolling statistics
}

# Get predictions
predictions = hybrid.predict(context, top_k=5)

for app, score in predictions:
    print(f"{app}: {score:.3f}")
```

Output:
```
chrome: 0.905
vscode: 0.889
terminal: 0.803
slack: 0.762
spotify: 0.552
```

## ðŸ“ Project Structure
```
app-usage-predictor/
â”œâ”€â”€ data_collection/
â”‚   â”œâ”€â”€ logger_x11.py          # Main data collector (X11)
â”‚   â”œâ”€â”€ logger_test.py         # Synthetic data generator
â”‚   â””â”€â”€ db_core.py             # Database schemas
â”‚
â”œâ”€â”€ data_processing/
â”‚   â”œâ”€â”€ preprocessing.py       # Bucketing, sessions, vocab
â”‚   â””â”€â”€ feature_engineering.py # Time features, rolling stats
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline.py            # Frequency-based baseline
â”‚   â”œâ”€â”€ tcn_model.py           # Temporal CNN
â”‚   â”œâ”€â”€ embeddings.py          # Skip-gram embeddings
â”‚   â”œâ”€â”€ association_rules.py   # FP-Growth rule mining
â”‚   â””â”€â”€ hybrid.py              # Combined predictor
â”‚
â”œâ”€â”€ training/
â”‚   â””â”€â”€ train_all.py           # Master training pipeline
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py             # Hit@K, MRR, Precision
â”‚   â””â”€â”€ ablation.py            # Model comparison
â”‚
â””â”€â”€ outputs/
    â”œâ”€â”€ models/                # Trained model weights
    â””â”€â”€ logs/                  # Training logs
```

## ðŸ”¬ Technical Details

### Data Processing

**Time Bucketing**: Events aggregated into 30-minute intervals
- Reduces noise from rapid window switching
- Enables efficient temporal modeling

**Sessionization**: Idle gaps >15 minutes define session boundaries
- Used for training embeddings and mining rules
- Average session: 8-12 app transitions

**Feature Engineering**:
- Cyclic time encoding (sin/cos for hour/day)
- Rolling statistics (24h, 7d, 14d usage counts)
- Recency features (buckets since last use)

### Model Architecture

**TCN Hyperparameters**:
- Hidden dim: 32
- Kernel size: 3
- Dilations: [1, 2, 4]
- Receptive field: 12 hours
- Parameters: 7,430
- Training: Adam (lr=1e-3), 20 epochs

**Embedding Hyperparameters**:
- Dimension: 16
- Window: 2 (skip-gram context)
- Learning rate: 0.01
- Training: Online (5 passes)

**Fusion Weights** (optimized):
- Î± (TCN): 0.5
- Î² (Embeddings): 0.3
- Î³ (Rules): 0.2

### Memory & Performance

- Model size: ~15MB total
- Inference latency: <100ms (target)
- Memory footprint: ~80MB runtime
- Training time: ~2 minutes (CPU)

## âš ï¸ Limitations

**Granularity**:
- Tracks application-level focus, not URLs or commands
- Window title parsing provides some context (e.g., `chrome:work:gmail`)
- Misses background processes (e.g., Spotify while coding)

**Platform**:
- Requires X11 session (Wayland restricts window introspection)
- Linux-specific (uses xdotool, xprintidle)
- Could be adapted for Windows/macOS

**Dataset**:
- Synthetic data used for development (21 days, 2094 events)
- Real data collection ongoing (need 2-3 weeks for robust training)
- Single-user patterns (not population-level)

**Model**:
- Vocabulary limited to frequently used apps (min_count=10)
- Cold start problem for new apps
- No temporal drift adaptation yet

## ðŸ”® Future Work

**Short-term** (planned):
- Retrain on real usage data (2-3 weeks collection)
- Add visualization dashboard (Plotly/Streamlit)
- Statistical significance testing (bootstrap CI)

**Medium-term** (possible):
- Contextual bandits for active recommendations
- Browser extension for URL-level tracking
- Shell integration for command-level context

**Long-term** (research):
- Cross-device learning (laptop + phone)
- Federated learning for privacy
- Multi-task prediction (app + duration + time-to-next)

## ðŸ“Š Ablation Study Results

Detailed comparison of model variants:

| Variant | Description | Hit@1 | Hit@3 | MRR |
|---------|-------------|-------|-------|-----|
| Baseline | Time-of-day + transitions | 0.277 | 0.755 | 0.529 |
| Hybrid (equal) | Î±=0.33, Î²=0.33, Î³=0.34 | 0.372 | 0.819 | 0.597 |
| Hybrid (TCN-heavy) | Î±=0.7, Î²=0.15, Î³=0.15 | 0.372 | 0.819 | 0.597 |
| **Hybrid (optimized)** | **Î±=0.5, Î²=0.3, Î³=0.2** | **0.372** | **0.819** | **0.597** |

**Insights**:
- All hybrid variants outperform baseline
- Weight sensitivity not visible on synthetic data
- Expect differentiation with real data (more complex patterns)

## ðŸ› ï¸ Development

**Run tests**:
```bash
pytest tests/
```

**Generate synthetic data** (for testing):
```bash
python data_collection/logger_test.py
```

**Inspect database**:
```bash
sqlite3 usage.db "SELECT COUNT(*) FROM app_events"
sqlite3 usage.db "SELECT app_id, COUNT(*) as cnt FROM app_events GROUP BY app_id ORDER BY cnt DESC"
```

## ðŸ“ Citation

If you use this project, please reference:
```
@misc{appusagepredictor2026,
  author = {Your Name},
  title = {Hybrid App Usage Prediction System},
  year = {2026},
  url = {https://github.com/yourusername/app-usage-predictor}
}
```

## ðŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

## ðŸ™ Acknowledgments

Algorithms implemented:
- TCN: Bai et al., 2018
- Skip-gram: Mikolov et al., 2013
- FP-Growth: Han et al., 2000

---

**Status**: âœ… Core system complete | ðŸ”„ Real data collection ongoing | ðŸ“ Documentation in progress